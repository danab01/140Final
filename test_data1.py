# -*- coding: utf-8 -*-
"""Test_Data1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gyY_Uuuq2RyKLbAtmkReQ5NPIYkhs7rr
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

import os 

os.chdir('/content/drive/MyDrive/Academics/~Harvard/3.JR./NEURO_140')

# load dataset
dataframe = pandas.read_csv("DM_data2.csv", delim_whitespace=True, header=None)
dataset = dataframe.values
# split into input (X) and output (Y) variables
X = dataset[:,:-1]
Y = dataset[:,-1]

# define base model
def baseline_model():
	# create model
	model = Sequential()
	model.add(Dense(36, input_dim=36, kernel_initializer='normal', activation='relu'))
	model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate model
estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)
kfold = KFold(n_splits=10)
results = cross_val_score(estimator, X, Y, cv=kfold)
print("Baseline: %.2f (%.2f) MSE" % (results.mean(), results.std()))
percent = str(100*abs(results.mean()/Y.mean()))
print("% error:" + percent)

# define deeper model
def deeper_model():
	# create model
	model = Sequential()
	model.add(Dense(36, input_dim=36, kernel_initializer='normal', activation='relu'))
	model.add(Dense(6, kernel_initializer='normal', activation ='relu'))
	model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate deeper model
estimator = KerasRegressor(build_fn=deeper_model, epochs=100, batch_size=5, verbose=0)
kfold = KFold(n_splits=10)
results = cross_val_score(estimator, X, Y, cv=kfold)
print("Deeper: %.2f (%.2f) MSE" % (results.mean(), results.std()))
percent = str(100*abs(results.mean()/Y.mean()))
print("% error:" + percent)

# define deeper model 2
def deeper_model2():
	# create model
	model = Sequential()
	model.add(Dense(36, input_dim=36, kernel_initializer='normal', activation='relu'))
	model.add(Dense(12, kernel_initializer='normal', activation ='relu'))
	model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate deeper model 2
estimator = KerasRegressor(build_fn=deeper_model2, epochs=100, batch_size=5, verbose=0)
kfold = KFold(n_splits=10)
results = cross_val_score(estimator, X, Y, cv=kfold)
print("Deeper: %.2f (%.2f) MSE" % (results.mean(), results.std()))
percent = str(100*abs(results.mean()/Y.mean()))
print("% error:" + percent)

# define wider model
def wider_model():
	# create model
	model = Sequential()
	model.add(Dense(48, input_dim=36, kernel_initializer='normal', activation='relu'))
	model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate wider model
estimator = KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)
kfold = KFold(n_splits=10)
results = cross_val_score(estimator, X, Y, cv=kfold)
print("Wider: %.2f (%.2f) MSE" % (results.mean(), results.std()))
percent = str(100*abs(results.mean()/Y.mean()))
print("% error:" + percent)

# define hybrid model
def hybrid_model():
	# create model
	model = Sequential()
	model.add(Dense(40, input_dim=36, kernel_initializer='normal', activation='relu'))
	model.add(Dense(10, kernel_initializer='normal', activation ='relu'))
	model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate hybrid model
estimator = KerasRegressor(build_fn=hybrid_model, epochs=100, batch_size=5, verbose=0)
kfold = KFold(n_splits=10)
results = cross_val_score(estimator, X, Y, cv=kfold)
print("Wider: %.2f (%.2f) MSE" % (results.mean(), results.std()))
percent = str(100*abs(results.mean()/Y.mean()))
print("% error:" + percent)

# define base inverse model
def base_inverse_model():
	# create model
	model = Sequential()
	model.add(Dense(1, input_dim=1, kernel_initializer='normal', activation='relu'))
	model.add(Dense(36, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate base inverse model
estimator = KerasRegressor(build_fn=base_inverse_model, epochs=100, batch_size=5, verbose=0)
kfold = KFold(n_splits=10)
results = cross_val_score(estimator, Y, X, cv=kfold)
print("Inverse: %.2f (%.2f) MSE" % (results.mean(), results.std()))

# define deep inverse model
def deep_inverse_model():
	# create model
	model = Sequential()
	model.add(Dense(1, input_dim=1, kernel_initializer='normal', activation='relu'))
	model.add(Dense(6, kernel_initializer='normal', activation ='relu'))
	model.add(Dense(36, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate deep inverse model
estimator = KerasRegressor(build_fn=deep_inverse_model, epochs=100, batch_size=5, verbose=0)
kfold = KFold(n_splits=10)
results = cross_val_score(estimator, Y, X, cv=kfold)
print("Inverse: %.2f (%.2f) MSE" % (results.mean(), results.std()))

# define wide inverse model
def inverse_model():
	# create model
	model = Sequential()
	model.add(Dense(6, input_dim=1, kernel_initializer='normal', activation='relu'))
	model.add(Dense(36, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate wide inverse model
estimator = KerasRegressor(build_fn=inverse_model, epochs=100, batch_size=5, verbose=0)
kfold = KFold(n_splits=10)
results = cross_val_score(estimator, Y, X, cv=kfold)
print("Inverse: %.2f (%.2f) MSE" % (results.mean(), results.std()))

model = inverse_model()
model.fit(Y, X, epochs=150, batch_size=10, verbose=0)

actuators = model.predict([100])

print(actuators)

